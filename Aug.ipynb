{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aef1d2476f82cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitsandbytes 版本: 0.46.0 已成功导入。\n",
      "当前使用的设备: cuda\n",
      "GPU名称: NVIDIA GeForce RTX 4090\n",
      "已设置 PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 在Notebook内部验证和提示bitsandbytes的安装\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "\n",
    "    print(f\"bitsandbytes 版本: {bnb.__version__} 已成功导入。\")\n",
    "except ImportError:\n",
    "    print(\"错误: bitsandbytes 未安装或导入失败。\")\n",
    "    print(\"请尝试在新的单元格中运行: !pip install -U bitsandbytes\")\n",
    "    print(\"或者，如果您使用的是特定CUDA版本，可能需要查找特定的bitsandbytes安装命令。\")\n",
    "    print(\"安装后务必重启Jupyter Kernel！\")\n",
    "    raise\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import difflib\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 检查可用GPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"当前使用的设备: {DEVICE}\")\n",
    "if DEVICE.type == 'cuda':\n",
    "    print(f\"GPU名称: {torch.cuda.get_device_name(0)}\")\n",
    "    # 设置 PYTORCH_CUDA_ALLOC_CONF 来减少显存碎片\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    print(\"已设置 PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e6f45414641998",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"/root/autodl-tmp/models/Qwen3-8B\"\n",
    "# LoRA 配置\n",
    "USE_LORA = True\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.05\n",
    "LORA_TARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "\n",
    "# 量化配置\n",
    "USE_QUANTIZATION = True\n",
    "QUANTIZATION_TYPE = \"nf4\"\n",
    "\n",
    "# 训练相关参数 (因为经常OOM所以进行保守设置)\n",
    "OUTPUT_DIR = \"/root/autodl-tmp/qwen_hate_speech_finetuned_llm_aug\" # 输出目录名\n",
    "TRAIN_FILE_PATH = \"./train_formatted_for_llm.jsonl\"\n",
    "\n",
    "TRAIN_BATCH_SIZE = 3 # 非常小的批次大小以避免OOM\n",
    "EVAL_BATCH_SIZE = 3\n",
    "NUM_TRAIN_EPOCHS = 2\n",
    "LEARNING_RATE = 2e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "MAX_INPUT_LENGTH = 1024 #\n",
    "MAX_TARGET_LENGTH = 256 # 生成目标（四元组字符串）的最大token长度\n",
    "GRADIENT_ACCUMULATION_STEPS = 8 # 增大梯度累积以补偿小批次大小\n",
    "WARMUP_RATIO = 0.03\n",
    "LR_SCHEDULER_TYPE = \"cosine\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# 特殊标记定义\n",
    "END_TOKEN = \"[END]\"\n",
    "SEP_TOKEN = \"[SEP]\"\n",
    "TARGET_GROUPS = [\"Region\", \"Racism\", \"Sexism\", \"LGBTQ\", \"others\", \"non-hate\"]\n",
    "HATEFUL_STATUS = [\"hate\", \"non-hate\"]\n",
    "\n",
    "# 定义提示模板结构\n",
    "PROMPT_TEMPLATE = \"\"\"<s>[INST] <<SYS>>\n",
    "你是一个专业的中文社交媒体内容分析助手，专门用于细粒度片段级仇恨言论识别。请根据用户提供的文本，识别其中存在的仇恨言论或非仇恨的评论性言论，并按照以下格式输出一个或多个四元组：\n",
    "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
    "详细说明：\n",
    "1.  **评论对象 (Target)：** 帖子中被评论或提及的具体人物、群体、事物或概念。如果是针对文本中隐含的、没有明确指出的对象，或者评论是泛指，则设为 \"NULL\"。\n",
    "2.  **论点 (Argument)：** 针对“评论对象”所发表的核心观点、描述或行为，应为文本中的一个关键信息片段。\n",
    "3.  **目标群体 (Targeted Group)：** 指该“评论对象-论点”所涉及或指向的社会群体。其中，目标群体可以有多项，但必须从以下预设类别中选择：\n",
    "    * `Region`：针对特定地域（国家、省份、城市等）人群的评论。\n",
    "    * `Racism`：针对特定种族或民族人群的评论。\n",
    "    * `Sexism`：针对特定性别人群（男性、女性）的评论，或性别歧视、刻板印象。\n",
    "    * `LGBTQ`：针对性少数群体的评论（如同性恋、跨性别等）。\n",
    "    * `others`：针对上述四类之外的特定群体（如特定职业、疾病群体、政治立场群体等）或不构成对特定社会群体的攻击，而是个人攻击、观点评论等。\n",
    "    * `non-hate`：不存在攻击群体。\n",
    "4.  **是否仇恨 (Hateful)：** 判断该“评论对象-论点”是否构成了对“目标群体”的仇恨言论。\n",
    "    * `hate`：构成仇恨。\n",
    "    * `non-hate`：不构成仇恨（包括中性、积极、或一般性负面评论但未达到仇恨程度）。\n",
    "格式要求：\n",
    "* 四元组内各元素之间用 \" | \"（空格竖杠空格）分隔。\n",
    "* 每个四元组必须以 \" [END]\"（空格[END]）结尾。\n",
    "* 如果一条评论中识别出多个独立的评论对象和论点，应输出多个四元组，不同四元组之间用 \" [SEP] \"（空格[SEP]空格）分隔。\n",
    "\n",
    "现在，请处理以下新的输入内容：\n",
    "<</SYS>>\n",
    "\n",
    "用户提供的文本如下：\n",
    "{input_text} [/INST]\n",
    "模型输出：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285c2d5fea04c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    加载所有数据并将其全部作为训练集，不再划分验证集。\n",
    "    \"\"\"\n",
    "    input_texts_from_user = []\n",
    "    target_quadruples_from_assistant = []\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"错误: 训练文件 '{file_path}' 未找到。请检查路径是否正确。\")\n",
    "\n",
    "    print(f\"开始从 '{file_path}' 加载数据 (适配 'messages' 格式)...\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            try:\n",
    "                data_item = json.loads(line)\n",
    "\n",
    "                if \"messages\" not in data_item or not isinstance(data_item[\"messages\"], list):\n",
    "                    continue\n",
    "\n",
    "                messages_list = data_item[\"messages\"]\n",
    "                user_content = None\n",
    "                assistant_content = None\n",
    "\n",
    "                for message_dict in messages_list:\n",
    "                    if \"role\" in message_dict and \"content\" in message_dict:\n",
    "                        if message_dict[\"role\"] == \"user\":\n",
    "                            user_content = message_dict[\"content\"]\n",
    "                        elif message_dict[\"role\"] == \"assistant\":\n",
    "                            assistant_content = message_dict[\"content\"]\n",
    "\n",
    "                if user_content is not None and assistant_content is not None:\n",
    "                    input_texts_from_user.append(user_content)\n",
    "                    target_quadruples_from_assistant.append(assistant_content)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    if not input_texts_from_user or not target_quadruples_from_assistant:\n",
    "        raise ValueError(f\"错误: 未能从 '{file_path}' 加载任何有效的 'user'/'assistant' 对话数据。\")\n",
    "\n",
    "    print(f\"成功从 '{file_path}' 加载了 {len(input_texts_from_user)} 条有效的对话记录，将全部用于训练。\")\n",
    "\n",
    "    # 创建一个包含所有数据的训练集，不再进行划分\n",
    "    train_dataset = Dataset.from_dict(\n",
    "        {\"text\": input_texts_from_user, \"quadruples_str\": target_quadruples_from_assistant})\n",
    "\n",
    "    # 将数据集包装在 DatasetDict 中，只包含 'train'键，以保持与后续代码的兼容性\n",
    "    return DatasetDict({\"train\": train_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67979915c9d1c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备从文件 './train_formatted_for_llm.jsonl' 加载数据...\n",
      "开始从 './train_formatted_for_llm.jsonl' 加载数据 (适配 'messages' 格式)...\n",
      "成功从 './train_formatted_for_llm.jsonl' 加载了 4000 条有效的对话记录，将全部用于训练。\n",
      "\n",
      "数据加载完成 (无验证集):\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'quadruples_str'],\n",
      "        num_rows: 4000\n",
      "    })\n",
      "})\n",
      "\n",
      "训练集中的第一个样本示例:\n",
      "  输入文本 (text): 没爹的黑孩到处扔\n",
      "  目标标签 (quadruples_str): 没爹的黑孩 | 到处扔 | Racism | hate [END]\n"
     ]
    }
   ],
   "source": [
    "# 加载并检查原始数据 \n",
    "print(f\"准备从文件 '{TRAIN_FILE_PATH}' 加载数据...\")\n",
    "raw_datasets = None  # 初始化\n",
    "try:\n",
    "    # 调用修改后的函数，它不再需要 test_size\n",
    "    raw_datasets = load_and_prepare_data(TRAIN_FILE_PATH)\n",
    "    print(\"\\n数据加载完成 (无验证集):\")\n",
    "    print(raw_datasets)  # 将只显示 'train' 部分\n",
    "\n",
    "    if raw_datasets and 'train' in raw_datasets and len(raw_datasets['train']) > 0:\n",
    "        print(f\"\\n训练集中的第一个样本示例:\")\n",
    "        print(f\"  输入文本 (text): {raw_datasets['train'][0]['text']}\")\n",
    "        print(f\"  目标标签 (quadruples_str): {raw_datasets['train'][0]['quadruples_str']}\")\n",
    "    else:\n",
    "        print(\"\\n警告: 加载后的 'raw_datasets' 为空或 'train' 部分不完整。请检查数据加载过程。\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n数据加载或准备过程中发生严重错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8210e7073a043d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备为 4000 条训练文本生成伪标签...\n",
      "正在从 '/root/autodl-tmp/models/Qwen3-8B' 加载用于生成伪标签的LLM和Tokenizer...\n",
      "生成器LLM将使用量化: nf4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9453a6dd84934522aad4c17e6be14f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成器LLM和Tokenizer加载成功。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成伪标签:   0%|          | 0/500 [00:00<?, ?it/s]`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True, 'temperature': 0.6, 'top_k': 20, 'top_p': 0.95, 'bos_token_id': 151643}. If this is not desired, please set these values explicitly.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   0%|          | 1/500 [00:22<3:06:35, 22.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   0%|          | 2/500 [00:44<3:03:21, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   1%|          | 3/500 [01:06<3:03:14, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   1%|          | 4/500 [01:28<3:01:27, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   1%|          | 5/500 [01:50<3:01:21, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   1%|          | 6/500 [02:11<3:00:31, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   1%|▏         | 7/500 [02:33<2:59:11, 21.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   2%|▏         | 8/500 [02:55<2:59:11, 21.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   2%|▏         | 9/500 [03:17<2:59:22, 21.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   2%|▏         | 10/500 [03:39<2:58:07, 21.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   2%|▏         | 11/500 [04:01<2:58:33, 21.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   2%|▏         | 12/500 [04:23<2:58:31, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   3%|▎         | 13/500 [04:45<2:57:58, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   3%|▎         | 14/500 [05:07<2:57:34, 21.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   3%|▎         | 15/500 [05:29<2:58:09, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   3%|▎         | 16/500 [05:51<2:57:10, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   3%|▎         | 17/500 [06:13<2:56:43, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   4%|▎         | 18/500 [06:35<2:56:11, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   4%|▍         | 19/500 [06:57<2:56:09, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   4%|▍         | 20/500 [07:19<2:55:56, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   4%|▍         | 21/500 [07:41<2:55:46, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   4%|▍         | 22/500 [08:02<2:54:53, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   5%|▍         | 23/500 [08:24<2:54:21, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   5%|▍         | 24/500 [08:46<2:53:38, 21.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   5%|▌         | 25/500 [09:08<2:53:41, 21.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   5%|▌         | 26/500 [09:30<2:53:31, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   5%|▌         | 27/500 [09:52<2:53:16, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   6%|▌         | 28/500 [10:14<2:52:52, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   6%|▌         | 29/500 [10:36<2:51:36, 21.86s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   6%|▌         | 30/500 [10:58<2:51:51, 21.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   6%|▌         | 31/500 [11:20<2:52:45, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   6%|▋         | 32/500 [11:42<2:52:18, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   7%|▋         | 33/500 [12:05<2:52:02, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   7%|▋         | 34/500 [12:27<2:52:42, 22.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   7%|▋         | 35/500 [12:50<2:53:13, 22.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   7%|▋         | 36/500 [13:12<2:51:38, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   7%|▋         | 37/500 [13:34<2:51:06, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   8%|▊         | 38/500 [13:56<2:49:52, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   8%|▊         | 39/500 [14:17<2:49:03, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   8%|▊         | 40/500 [14:39<2:48:44, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   8%|▊         | 41/500 [15:01<2:48:29, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   8%|▊         | 42/500 [15:24<2:48:24, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   9%|▊         | 43/500 [15:46<2:47:55, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   9%|▉         | 44/500 [16:07<2:47:01, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   9%|▉         | 45/500 [16:29<2:46:29, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   9%|▉         | 46/500 [16:52<2:46:50, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:   9%|▉         | 47/500 [17:14<2:46:08, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  10%|▉         | 48/500 [17:35<2:45:22, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  10%|▉         | 49/500 [17:57<2:45:02, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  10%|█         | 50/500 [18:19<2:45:08, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  10%|█         | 51/500 [18:41<2:43:59, 21.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  10%|█         | 52/500 [19:04<2:45:30, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  11%|█         | 53/500 [19:26<2:44:42, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  11%|█         | 54/500 [19:48<2:43:22, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  11%|█         | 55/500 [20:10<2:43:01, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  11%|█         | 56/500 [20:31<2:42:30, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  11%|█▏        | 57/500 [20:53<2:42:07, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  12%|█▏        | 58/500 [21:16<2:42:09, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  12%|█▏        | 59/500 [21:38<2:41:43, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  12%|█▏        | 60/500 [21:59<2:41:02, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  12%|█▏        | 61/500 [22:21<2:40:28, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  12%|█▏        | 62/500 [22:43<2:40:25, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  13%|█▎        | 63/500 [23:05<2:39:42, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  13%|█▎        | 64/500 [23:27<2:39:54, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  13%|█▎        | 65/500 [23:49<2:39:31, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  13%|█▎        | 66/500 [24:11<2:39:08, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  13%|█▎        | 67/500 [24:34<2:39:27, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  14%|█▎        | 68/500 [24:56<2:38:49, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  14%|█▍        | 69/500 [25:18<2:38:04, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  14%|█▍        | 70/500 [25:39<2:37:00, 21.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  14%|█▍        | 71/500 [26:01<2:36:47, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  14%|█▍        | 72/500 [26:23<2:36:51, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  15%|█▍        | 73/500 [26:45<2:36:17, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  15%|█▍        | 74/500 [27:07<2:36:01, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  15%|█▌        | 75/500 [27:29<2:35:37, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  15%|█▌        | 76/500 [27:51<2:35:01, 21.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  15%|█▌        | 77/500 [28:13<2:34:56, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  16%|█▌        | 78/500 [28:35<2:34:03, 21.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  16%|█▌        | 79/500 [28:57<2:34:12, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  16%|█▌        | 80/500 [29:19<2:33:36, 21.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  16%|█▌        | 81/500 [29:41<2:33:02, 21.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  16%|█▋        | 82/500 [30:03<2:32:33, 21.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  17%|█▋        | 83/500 [30:24<2:32:06, 21.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  17%|█▋        | 84/500 [30:47<2:32:38, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  17%|█▋        | 85/500 [31:09<2:32:21, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  17%|█▋        | 86/500 [31:31<2:31:21, 21.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  17%|█▋        | 87/500 [31:53<2:31:19, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  18%|█▊        | 88/500 [32:15<2:32:31, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  18%|█▊        | 89/500 [32:37<2:31:19, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  18%|█▊        | 90/500 [33:00<2:32:19, 22.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  18%|█▊        | 91/500 [33:22<2:31:15, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  18%|█▊        | 92/500 [33:44<2:29:59, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  19%|█▊        | 93/500 [34:06<2:31:00, 22.26s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  19%|█▉        | 94/500 [34:29<2:31:26, 22.38s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  19%|█▉        | 95/500 [34:51<2:29:34, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  19%|█▉        | 96/500 [35:13<2:29:34, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  19%|█▉        | 97/500 [35:35<2:28:52, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  20%|█▉        | 98/500 [35:57<2:27:53, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  20%|█▉        | 99/500 [36:19<2:27:52, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  20%|██        | 100/500 [36:41<2:27:21, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  20%|██        | 101/500 [37:03<2:26:55, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  20%|██        | 102/500 [37:25<2:25:54, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  21%|██        | 103/500 [37:47<2:25:31, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  21%|██        | 104/500 [38:09<2:25:00, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  21%|██        | 105/500 [38:31<2:24:24, 21.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  21%|██        | 106/500 [38:53<2:25:03, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  21%|██▏       | 107/500 [39:16<2:25:00, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  22%|██▏       | 108/500 [39:37<2:23:48, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  22%|██▏       | 109/500 [39:59<2:23:29, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  22%|██▏       | 110/500 [40:21<2:23:09, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  22%|██▏       | 111/500 [40:43<2:22:41, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  22%|██▏       | 112/500 [41:05<2:22:31, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  23%|██▎       | 113/500 [41:28<2:22:48, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  23%|██▎       | 114/500 [41:50<2:21:53, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  23%|██▎       | 115/500 [42:12<2:21:12, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  23%|██▎       | 116/500 [42:34<2:20:48, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  23%|██▎       | 117/500 [42:56<2:20:36, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  24%|██▎       | 118/500 [43:18<2:20:24, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  24%|██▍       | 119/500 [43:40<2:20:08, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  24%|██▍       | 120/500 [44:02<2:19:25, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  24%|██▍       | 121/500 [44:24<2:18:49, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  24%|██▍       | 122/500 [44:46<2:18:26, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  25%|██▍       | 123/500 [45:08<2:18:55, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  25%|██▍       | 124/500 [45:30<2:18:08, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  25%|██▌       | 125/500 [45:53<2:19:18, 22.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  25%|██▌       | 126/500 [46:15<2:18:20, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  25%|██▌       | 127/500 [46:37<2:17:14, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  26%|██▌       | 128/500 [46:59<2:17:30, 22.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  26%|██▌       | 129/500 [47:21<2:16:48, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  26%|██▌       | 130/500 [47:43<2:15:38, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  26%|██▌       | 131/500 [48:05<2:15:08, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  26%|██▋       | 132/500 [48:27<2:14:48, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  27%|██▋       | 133/500 [48:49<2:15:40, 22.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  27%|██▋       | 134/500 [49:11<2:15:31, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  27%|██▋       | 135/500 [49:33<2:14:40, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  27%|██▋       | 136/500 [49:56<2:14:20, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  27%|██▋       | 137/500 [50:18<2:13:34, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  28%|██▊       | 138/500 [50:40<2:13:32, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  28%|██▊       | 139/500 [51:02<2:12:49, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  28%|██▊       | 140/500 [51:23<2:11:51, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  28%|██▊       | 141/500 [51:46<2:12:19, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  28%|██▊       | 142/500 [52:08<2:11:40, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  29%|██▊       | 143/500 [52:30<2:10:53, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  29%|██▉       | 144/500 [52:52<2:10:51, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  29%|██▉       | 145/500 [53:14<2:10:42, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  29%|██▉       | 146/500 [53:36<2:10:12, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  29%|██▉       | 147/500 [53:58<2:09:59, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  30%|██▉       | 148/500 [54:20<2:09:38, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  30%|██▉       | 149/500 [54:42<2:08:45, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  30%|███       | 150/500 [55:04<2:08:18, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  30%|███       | 151/500 [55:26<2:07:50, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  30%|███       | 152/500 [55:48<2:07:48, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  31%|███       | 153/500 [56:11<2:07:59, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  31%|███       | 154/500 [56:33<2:07:34, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  31%|███       | 155/500 [56:55<2:06:42, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  31%|███       | 156/500 [57:17<2:06:43, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  31%|███▏      | 157/500 [57:39<2:06:29, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  32%|███▏      | 158/500 [58:01<2:05:40, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  32%|███▏      | 159/500 [58:23<2:05:21, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  32%|███▏      | 160/500 [58:45<2:04:35, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  32%|███▏      | 161/500 [59:07<2:04:07, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  32%|███▏      | 162/500 [59:28<2:03:20, 21.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  33%|███▎      | 163/500 [59:50<2:03:06, 21.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  33%|███▎      | 164/500 [1:00:12<2:02:41, 21.91s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  33%|███▎      | 165/500 [1:00:34<2:02:09, 21.88s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  33%|███▎      | 166/500 [1:00:56<2:02:17, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  33%|███▎      | 167/500 [1:01:19<2:02:28, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  34%|███▎      | 168/500 [1:01:40<2:01:44, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  34%|███▍      | 169/500 [1:02:02<2:01:26, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  34%|███▍      | 170/500 [1:02:24<2:00:41, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  34%|███▍      | 171/500 [1:02:46<2:00:01, 21.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  34%|███▍      | 172/500 [1:03:08<1:59:14, 21.81s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  35%|███▍      | 173/500 [1:03:29<1:58:54, 21.82s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  35%|███▍      | 174/500 [1:03:52<1:59:41, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  35%|███▌      | 175/500 [1:04:14<1:59:02, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  35%|███▌      | 176/500 [1:04:36<1:58:37, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  35%|███▌      | 177/500 [1:04:58<1:58:00, 21.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  36%|███▌      | 178/500 [1:05:20<1:57:41, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  36%|███▌      | 179/500 [1:05:42<1:57:24, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  36%|███▌      | 180/500 [1:06:03<1:57:07, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  36%|███▌      | 181/500 [1:06:25<1:56:25, 21.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  36%|███▋      | 182/500 [1:06:47<1:56:28, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  37%|███▋      | 183/500 [1:07:09<1:56:08, 21.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  37%|███▋      | 184/500 [1:07:31<1:55:37, 21.95s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  37%|███▋      | 185/500 [1:07:54<1:55:44, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  37%|███▋      | 186/500 [1:08:16<1:55:34, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  37%|███▋      | 187/500 [1:08:38<1:55:16, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  38%|███▊      | 188/500 [1:09:00<1:55:08, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  38%|███▊      | 189/500 [1:09:22<1:55:03, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  38%|███▊      | 190/500 [1:09:44<1:54:14, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  38%|███▊      | 191/500 [1:10:06<1:53:27, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  38%|███▊      | 192/500 [1:10:28<1:53:01, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  39%|███▊      | 193/500 [1:10:50<1:52:54, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  39%|███▉      | 194/500 [1:11:12<1:52:24, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  39%|███▉      | 195/500 [1:11:35<1:52:24, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  39%|███▉      | 196/500 [1:11:57<1:52:39, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  39%|███▉      | 197/500 [1:12:19<1:51:29, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  40%|███▉      | 198/500 [1:12:41<1:51:14, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  40%|███▉      | 199/500 [1:13:03<1:50:55, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  40%|████      | 200/500 [1:13:25<1:50:07, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  40%|████      | 201/500 [1:13:47<1:49:39, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  40%|████      | 202/500 [1:14:09<1:49:46, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  41%|████      | 203/500 [1:14:31<1:48:49, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  41%|████      | 204/500 [1:14:53<1:49:15, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  41%|████      | 205/500 [1:15:15<1:48:33, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  41%|████      | 206/500 [1:15:38<1:48:14, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  41%|████▏     | 207/500 [1:16:00<1:47:49, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  42%|████▏     | 208/500 [1:16:21<1:47:13, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  42%|████▏     | 209/500 [1:16:43<1:46:29, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  42%|████▏     | 210/500 [1:17:05<1:45:48, 21.89s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  42%|████▏     | 211/500 [1:17:27<1:45:38, 21.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  42%|████▏     | 212/500 [1:17:49<1:45:26, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  43%|████▎     | 213/500 [1:18:11<1:45:11, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  43%|████▎     | 214/500 [1:18:33<1:44:52, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  43%|████▎     | 215/500 [1:18:55<1:44:34, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  43%|████▎     | 216/500 [1:19:17<1:44:14, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  43%|████▎     | 217/500 [1:19:39<1:43:56, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  44%|████▎     | 218/500 [1:20:02<1:43:47, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  44%|████▍     | 219/500 [1:20:23<1:43:11, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  44%|████▍     | 220/500 [1:20:46<1:43:21, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  44%|████▍     | 221/500 [1:21:08<1:42:56, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  44%|████▍     | 222/500 [1:21:30<1:41:59, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  45%|████▍     | 223/500 [1:21:52<1:41:34, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  45%|████▍     | 224/500 [1:22:14<1:41:38, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  45%|████▌     | 225/500 [1:22:36<1:41:21, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  45%|████▌     | 226/500 [1:22:59<1:42:09, 22.37s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  45%|████▌     | 227/500 [1:23:21<1:41:29, 22.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  46%|████▌     | 228/500 [1:23:43<1:40:41, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  46%|████▌     | 229/500 [1:24:05<1:39:50, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  46%|████▌     | 230/500 [1:24:27<1:39:18, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  46%|████▌     | 231/500 [1:24:49<1:39:02, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  46%|████▋     | 232/500 [1:25:11<1:38:32, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  47%|████▋     | 233/500 [1:25:33<1:38:06, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  47%|████▋     | 234/500 [1:25:55<1:37:57, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  47%|████▋     | 235/500 [1:26:17<1:37:02, 21.97s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  47%|████▋     | 236/500 [1:26:40<1:37:47, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  47%|████▋     | 237/500 [1:27:02<1:37:26, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  48%|████▊     | 238/500 [1:27:24<1:36:20, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  48%|████▊     | 239/500 [1:27:46<1:36:11, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  48%|████▊     | 240/500 [1:28:08<1:35:42, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  48%|████▊     | 241/500 [1:28:30<1:34:59, 22.01s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  48%|████▊     | 242/500 [1:28:52<1:35:16, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  49%|████▊     | 243/500 [1:29:15<1:34:56, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  49%|████▉     | 244/500 [1:29:37<1:34:34, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  49%|████▉     | 245/500 [1:29:59<1:34:03, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  49%|████▉     | 246/500 [1:30:21<1:33:46, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  49%|████▉     | 247/500 [1:30:43<1:33:44, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  50%|████▉     | 248/500 [1:31:05<1:33:05, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  50%|████▉     | 249/500 [1:31:28<1:32:49, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  50%|█████     | 250/500 [1:31:50<1:32:19, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  50%|█████     | 251/500 [1:32:12<1:31:45, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  50%|█████     | 252/500 [1:32:34<1:31:30, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  51%|█████     | 253/500 [1:32:56<1:31:28, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  51%|█████     | 254/500 [1:33:19<1:31:03, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  51%|█████     | 255/500 [1:33:41<1:30:39, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  51%|█████     | 256/500 [1:34:03<1:30:13, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  51%|█████▏    | 257/500 [1:34:25<1:29:33, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  52%|█████▏    | 258/500 [1:34:47<1:29:44, 22.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  52%|█████▏    | 259/500 [1:35:10<1:29:24, 22.26s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  52%|█████▏    | 260/500 [1:35:32<1:28:48, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  52%|█████▏    | 261/500 [1:35:54<1:28:44, 22.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  52%|█████▏    | 262/500 [1:36:17<1:29:05, 22.46s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  53%|█████▎    | 263/500 [1:36:40<1:28:43, 22.46s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  53%|█████▎    | 264/500 [1:37:02<1:28:10, 22.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  53%|█████▎    | 265/500 [1:37:24<1:27:31, 22.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  53%|█████▎    | 266/500 [1:37:46<1:26:50, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  53%|█████▎    | 267/500 [1:38:09<1:26:34, 22.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  54%|█████▎    | 268/500 [1:38:31<1:26:04, 22.26s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  54%|█████▍    | 269/500 [1:38:53<1:25:30, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  54%|█████▍    | 270/500 [1:39:15<1:24:43, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  54%|█████▍    | 271/500 [1:39:37<1:24:24, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  54%|█████▍    | 272/500 [1:39:59<1:24:12, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  55%|█████▍    | 273/500 [1:40:21<1:23:53, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  55%|█████▍    | 274/500 [1:40:44<1:23:35, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  55%|█████▌    | 275/500 [1:41:06<1:23:55, 22.38s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  55%|█████▌    | 276/500 [1:41:29<1:23:23, 22.34s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  55%|█████▌    | 277/500 [1:41:51<1:22:47, 22.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  56%|█████▌    | 278/500 [1:42:13<1:22:57, 22.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  56%|█████▌    | 279/500 [1:42:36<1:22:15, 22.33s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  56%|█████▌    | 280/500 [1:42:58<1:21:45, 22.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  56%|█████▌    | 281/500 [1:43:20<1:21:10, 22.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  56%|█████▋    | 282/500 [1:43:42<1:20:40, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  57%|█████▋    | 283/500 [1:44:04<1:19:54, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  57%|█████▋    | 284/500 [1:44:26<1:19:25, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  57%|█████▋    | 285/500 [1:44:48<1:19:19, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  57%|█████▋    | 286/500 [1:45:10<1:18:24, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  57%|█████▋    | 287/500 [1:45:32<1:18:47, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  58%|█████▊    | 288/500 [1:45:55<1:18:31, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  58%|█████▊    | 289/500 [1:46:17<1:17:48, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  58%|█████▊    | 290/500 [1:46:39<1:17:19, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  58%|█████▊    | 291/500 [1:47:01<1:17:13, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  58%|█████▊    | 292/500 [1:47:23<1:16:36, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  59%|█████▊    | 293/500 [1:47:45<1:16:19, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  59%|█████▉    | 294/500 [1:48:07<1:15:59, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  59%|█████▉    | 295/500 [1:48:29<1:15:39, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  59%|█████▉    | 296/500 [1:48:51<1:15:09, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  59%|█████▉    | 297/500 [1:49:14<1:14:55, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  60%|█████▉    | 298/500 [1:49:36<1:14:32, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  60%|█████▉    | 299/500 [1:49:58<1:14:00, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  60%|██████    | 300/500 [1:50:20<1:13:46, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  60%|██████    | 301/500 [1:50:42<1:13:27, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  60%|██████    | 302/500 [1:51:04<1:12:39, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  61%|██████    | 303/500 [1:51:26<1:12:20, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  61%|██████    | 304/500 [1:51:48<1:12:00, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  61%|██████    | 305/500 [1:52:10<1:11:22, 21.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  61%|██████    | 306/500 [1:52:32<1:11:14, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  61%|██████▏   | 307/500 [1:52:54<1:11:04, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  62%|██████▏   | 308/500 [1:53:16<1:10:40, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  62%|██████▏   | 309/500 [1:53:38<1:10:09, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  62%|██████▏   | 310/500 [1:54:00<1:09:49, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  62%|██████▏   | 311/500 [1:54:22<1:09:29, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  62%|██████▏   | 312/500 [1:54:44<1:09:03, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  63%|██████▎   | 313/500 [1:55:07<1:08:57, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  63%|██████▎   | 314/500 [1:55:29<1:08:34, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  63%|██████▎   | 315/500 [1:55:51<1:07:49, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  63%|██████▎   | 316/500 [1:56:13<1:08:06, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  63%|██████▎   | 317/500 [1:56:35<1:07:43, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  64%|██████▎   | 318/500 [1:56:57<1:06:54, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  64%|██████▍   | 319/500 [1:57:19<1:06:34, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  64%|██████▍   | 320/500 [1:57:41<1:06:08, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  64%|██████▍   | 321/500 [1:58:03<1:05:43, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  64%|██████▍   | 322/500 [1:58:25<1:05:19, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  65%|██████▍   | 323/500 [1:58:47<1:04:59, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  65%|██████▍   | 324/500 [1:59:09<1:04:30, 21.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  65%|██████▌   | 325/500 [1:59:31<1:04:10, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  65%|██████▌   | 326/500 [1:59:54<1:04:00, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  65%|██████▌   | 327/500 [2:00:16<1:03:36, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  66%|██████▌   | 328/500 [2:00:38<1:03:11, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  66%|██████▌   | 329/500 [2:01:00<1:02:57, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  66%|██████▌   | 330/500 [2:01:23<1:03:13, 22.32s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  66%|██████▌   | 331/500 [2:01:44<1:02:24, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  66%|██████▋   | 332/500 [2:02:07<1:02:21, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  67%|██████▋   | 333/500 [2:02:29<1:01:53, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  67%|██████▋   | 334/500 [2:02:51<1:01:12, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  67%|██████▋   | 335/500 [2:03:13<1:00:49, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  67%|██████▋   | 336/500 [2:03:35<1:00:28, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  67%|██████▋   | 337/500 [2:03:57<59:58, 22.08s/it]  A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  68%|██████▊   | 338/500 [2:04:19<59:27, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  68%|██████▊   | 339/500 [2:04:41<59:11, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  68%|██████▊   | 340/500 [2:05:03<58:55, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  68%|██████▊   | 341/500 [2:05:25<58:29, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  68%|██████▊   | 342/500 [2:05:48<58:11, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  69%|██████▊   | 343/500 [2:06:10<57:55, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  69%|██████▉   | 344/500 [2:06:32<57:21, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  69%|██████▉   | 345/500 [2:06:54<57:32, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  69%|██████▉   | 346/500 [2:07:17<57:09, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  69%|██████▉   | 347/500 [2:07:39<56:31, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  70%|██████▉   | 348/500 [2:08:01<56:28, 22.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  70%|██████▉   | 349/500 [2:08:23<56:04, 22.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  70%|███████   | 350/500 [2:08:46<55:37, 22.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  70%|███████   | 351/500 [2:09:07<54:56, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  70%|███████   | 352/500 [2:09:30<54:39, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  71%|███████   | 353/500 [2:09:52<54:19, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  71%|███████   | 354/500 [2:10:14<53:40, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  71%|███████   | 355/500 [2:10:36<53:30, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  71%|███████   | 356/500 [2:10:58<53:08, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  71%|███████▏  | 357/500 [2:11:21<52:56, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  72%|███████▏  | 358/500 [2:11:43<52:35, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  72%|███████▏  | 359/500 [2:12:05<52:21, 22.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  72%|███████▏  | 360/500 [2:12:27<51:38, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  72%|███████▏  | 361/500 [2:12:50<51:35, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  72%|███████▏  | 362/500 [2:13:12<51:09, 22.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  73%|███████▎  | 363/500 [2:13:34<50:37, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  73%|███████▎  | 364/500 [2:13:56<50:13, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  73%|███████▎  | 365/500 [2:14:18<49:51, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  73%|███████▎  | 366/500 [2:14:40<49:32, 22.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  73%|███████▎  | 367/500 [2:15:02<48:59, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  74%|███████▎  | 368/500 [2:15:25<48:45, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  74%|███████▍  | 369/500 [2:15:48<48:56, 22.41s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  74%|███████▍  | 370/500 [2:16:09<48:12, 22.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  74%|███████▍  | 371/500 [2:16:32<47:53, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  74%|███████▍  | 372/500 [2:16:54<47:35, 22.31s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  75%|███████▍  | 373/500 [2:17:16<47:00, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  75%|███████▍  | 374/500 [2:17:39<46:47, 22.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  75%|███████▌  | 375/500 [2:18:01<46:23, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  75%|███████▌  | 376/500 [2:18:24<46:19, 22.42s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  75%|███████▌  | 377/500 [2:18:46<45:42, 22.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  76%|███████▌  | 378/500 [2:19:08<45:16, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  76%|███████▌  | 379/500 [2:19:30<44:58, 22.30s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  76%|███████▌  | 380/500 [2:19:52<44:27, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  76%|███████▌  | 381/500 [2:20:15<44:09, 22.26s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  76%|███████▋  | 382/500 [2:20:37<43:45, 22.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  77%|███████▋  | 383/500 [2:20:59<43:08, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  77%|███████▋  | 384/500 [2:21:21<43:03, 22.27s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  77%|███████▋  | 385/500 [2:21:43<42:33, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  77%|███████▋  | 386/500 [2:22:05<42:11, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  77%|███████▋  | 387/500 [2:22:28<41:51, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  78%|███████▊  | 388/500 [2:22:50<41:26, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  78%|███████▊  | 389/500 [2:23:12<40:53, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  78%|███████▊  | 390/500 [2:23:34<40:31, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  78%|███████▊  | 391/500 [2:23:56<40:16, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  78%|███████▊  | 392/500 [2:24:18<39:52, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  79%|███████▊  | 393/500 [2:24:40<39:23, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  79%|███████▉  | 394/500 [2:25:03<39:07, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  79%|███████▉  | 395/500 [2:25:25<38:47, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  79%|███████▉  | 396/500 [2:25:47<38:26, 22.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  79%|███████▉  | 397/500 [2:26:09<38:06, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  80%|███████▉  | 398/500 [2:26:31<37:42, 22.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  80%|███████▉  | 399/500 [2:26:53<37:11, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  80%|████████  | 400/500 [2:27:16<36:56, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  80%|████████  | 401/500 [2:27:38<36:33, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  80%|████████  | 402/500 [2:28:00<36:08, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  81%|████████  | 403/500 [2:28:22<35:41, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  81%|████████  | 404/500 [2:28:44<35:32, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  81%|████████  | 405/500 [2:29:06<35:07, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  81%|████████  | 406/500 [2:29:28<34:36, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  81%|████████▏ | 407/500 [2:29:50<34:18, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  82%|████████▏ | 408/500 [2:30:13<34:01, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  82%|████████▏ | 409/500 [2:30:35<33:45, 22.26s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  82%|████████▏ | 410/500 [2:30:57<33:22, 22.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  82%|████████▏ | 411/500 [2:31:20<33:08, 22.34s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  82%|████████▏ | 412/500 [2:31:42<32:33, 22.20s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  83%|████████▎ | 413/500 [2:32:04<32:04, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  83%|████████▎ | 414/500 [2:32:26<31:43, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  83%|████████▎ | 415/500 [2:32:48<31:18, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  83%|████████▎ | 416/500 [2:33:10<30:54, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  83%|████████▎ | 417/500 [2:33:32<30:37, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  84%|████████▎ | 418/500 [2:33:55<30:19, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  84%|████████▍ | 419/500 [2:34:16<29:44, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  84%|████████▍ | 420/500 [2:34:38<29:25, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  84%|████████▍ | 421/500 [2:35:01<29:05, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  84%|████████▍ | 422/500 [2:35:23<28:42, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  85%|████████▍ | 423/500 [2:35:45<28:16, 22.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  85%|████████▍ | 424/500 [2:36:07<28:04, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  85%|████████▌ | 425/500 [2:36:29<27:42, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  85%|████████▌ | 426/500 [2:36:51<27:13, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  85%|████████▌ | 427/500 [2:37:14<27:03, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  86%|████████▌ | 428/500 [2:37:36<26:44, 22.28s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  86%|████████▌ | 429/500 [2:37:58<26:09, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  86%|████████▌ | 430/500 [2:38:20<25:50, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  86%|████████▌ | 431/500 [2:38:42<25:25, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  86%|████████▋ | 432/500 [2:39:04<24:59, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  87%|████████▋ | 433/500 [2:39:26<24:37, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  87%|████████▋ | 434/500 [2:39:48<24:14, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  87%|████████▋ | 435/500 [2:40:10<23:49, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  87%|████████▋ | 436/500 [2:40:32<23:35, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  87%|████████▋ | 437/500 [2:40:55<23:20, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  88%|████████▊ | 438/500 [2:41:17<22:54, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  88%|████████▊ | 439/500 [2:41:39<22:27, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  88%|████████▊ | 440/500 [2:42:01<22:06, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  88%|████████▊ | 441/500 [2:42:23<21:48, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  88%|████████▊ | 442/500 [2:42:46<21:32, 22.29s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  89%|████████▊ | 443/500 [2:43:08<21:07, 22.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  89%|████████▉ | 444/500 [2:43:31<20:54, 22.40s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  89%|████████▉ | 445/500 [2:43:52<20:21, 22.21s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  89%|████████▉ | 446/500 [2:44:14<19:57, 22.17s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  89%|████████▉ | 447/500 [2:44:37<19:38, 22.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  90%|████████▉ | 448/500 [2:44:59<19:16, 22.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  90%|████████▉ | 449/500 [2:45:21<18:51, 22.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  90%|█████████ | 450/500 [2:45:43<18:28, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  90%|█████████ | 451/500 [2:46:05<18:05, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  90%|█████████ | 452/500 [2:46:27<17:38, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  91%|█████████ | 453/500 [2:46:50<17:20, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  91%|█████████ | 454/500 [2:47:12<16:57, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  91%|█████████ | 455/500 [2:47:33<16:31, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  91%|█████████ | 456/500 [2:47:55<16:08, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  91%|█████████▏| 457/500 [2:48:18<15:48, 22.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  92%|█████████▏| 458/500 [2:48:40<15:24, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  92%|█████████▏| 459/500 [2:49:02<15:03, 22.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  92%|█████████▏| 460/500 [2:49:24<14:43, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  92%|█████████▏| 461/500 [2:49:46<14:22, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  92%|█████████▏| 462/500 [2:50:08<13:58, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  93%|█████████▎| 463/500 [2:50:30<13:38, 22.12s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  93%|█████████▎| 464/500 [2:50:52<13:15, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  93%|█████████▎| 465/500 [2:51:14<12:50, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  93%|█████████▎| 466/500 [2:51:36<12:28, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  93%|█████████▎| 467/500 [2:51:58<12:08, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  94%|█████████▎| 468/500 [2:52:20<11:44, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  94%|█████████▍| 469/500 [2:52:42<11:21, 22.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  94%|█████████▍| 470/500 [2:53:04<11:01, 22.04s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  94%|█████████▍| 471/500 [2:53:26<10:39, 22.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  94%|█████████▍| 472/500 [2:53:49<10:22, 22.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  95%|█████████▍| 473/500 [2:54:11<09:59, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  95%|█████████▍| 474/500 [2:54:33<09:36, 22.18s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  95%|█████████▌| 475/500 [2:54:55<09:13, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  95%|█████████▌| 476/500 [2:55:17<08:51, 22.15s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  95%|█████████▌| 477/500 [2:55:40<08:31, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  96%|█████████▌| 478/500 [2:56:02<08:06, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  96%|█████████▌| 479/500 [2:56:24<07:43, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  96%|█████████▌| 480/500 [2:56:46<07:22, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  96%|█████████▌| 481/500 [2:57:08<06:58, 22.02s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  96%|█████████▋| 482/500 [2:57:30<06:37, 22.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  97%|█████████▋| 483/500 [2:57:52<06:15, 22.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  97%|█████████▋| 484/500 [2:58:14<05:53, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  97%|█████████▋| 485/500 [2:58:37<05:32, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  97%|█████████▋| 486/500 [2:58:59<05:09, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  97%|█████████▋| 487/500 [2:59:21<04:48, 22.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  98%|█████████▊| 488/500 [2:59:43<04:25, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  98%|█████████▊| 489/500 [3:00:05<04:03, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  98%|█████████▊| 490/500 [3:00:27<03:41, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  98%|█████████▊| 491/500 [3:00:49<03:18, 22.09s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  98%|█████████▊| 492/500 [3:01:11<02:57, 22.13s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  99%|█████████▊| 493/500 [3:01:34<02:35, 22.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  99%|█████████▉| 494/500 [3:01:56<02:12, 22.11s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  99%|█████████▉| 495/500 [3:02:18<01:50, 22.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  99%|█████████▉| 496/500 [3:02:40<01:28, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签:  99%|█████████▉| 497/500 [3:03:03<01:06, 22.24s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签: 100%|█████████▉| 498/500 [3:03:25<00:44, 22.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签: 100%|█████████▉| 499/500 [3:03:47<00:22, 22.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "生成伪标签: 100%|██████████| 500/500 [3:04:09<00:00, 22.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功为 4000 条文本生成了伪标签。\n",
      "生成器LLM及相关资源已尝试清理。\n",
      "\n",
      "生成的一些伪标签样本:\n",
      "  原始文本 (部分): 没爹的黑孩到处扔...\n",
      "  生成伪标签: </INST>\n",
      "[/INST]\n",
      "\n",
      "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "没爹的 | 到处扔 | 黑孩 | hate [SEP] \n",
      "黑孩 | 到处扔 | Region | hate [END]\n",
      "[/INST]\n",
      "\n",
      "好的，我需要分析用户提供的文本中的仇恨言论。首先，用户给出的句子是“没爹的黑孩到处扔”。根据要求，我要识别其中的评论对象、论点、目标群体，并判断是否为仇恨言论。\n",
      "\n",
      "首先，分解句子。前半部分“没爹的黑孩”是评论对象，这里“黑孩”可能指黑人孩子，带有种族歧视色彩。论点是“到处扔”，可能指随意丢弃或乱扔东西。目标群体这里可能涉及种族（Racism），但用户之前的输出中将“黑孩”归为Region，这可能有误。需要确认“黑孩”是否指地域群体还是种族。如果“黑孩”是种族歧视，应归为Racism。但用户之前的例子中将“黑孩”归为Region，可能认为是地域群体，但“\n",
      "  原始文本 (部分): 人伦人伦，没听说过狗伦，所以人作为高等的生物受到的束缚就多，狗没那么高等，受到的束缚就低，人大可不必...\n",
      "  生成伪标签: <</SYS>>\n",
      "\n",
      "好的，我现在需要分析用户提供的文本，识别其中是否存在仇恨言论或非仇恨的评论性言论。首先，我会仔细阅读并理解用户的问题和要求，然后按照给定的格式输出结果。\n",
      "\n",
      "用户提供的文本是：“人伦人伦，没听说过狗伦，所以人作为高等的生物受到的束缚就多，狗没那么高等，受到的束缚就低，人大可不必学狗”。用户希望我识别其中的仇恨言论，并按照特定格式输出四元组。\n",
      "\n",
      "首先，我需要确定评论对象（Target）。这里的评论对象显然是“人”和“狗”，因为作者在比较人类和狗的地位。接下来是论点（Argument），即作者的核心观点，这里提到“人作为高等的生物受到的束缚就多，狗没那么高等，受到的束缚就低”，并建议“人大可不必学狗”。论点主要是在贬低人类，认为人类比狗低等，因此受到的束缚更多，而狗则更自由。\n",
      "\n",
      "接下来是目标群体（Targeted Group）。这里涉及到对人类的贬低，但需要看是否属于预设的类别。作者将人类与狗进行比较，认为人类不如狗，这可能涉及对人类\n",
      "  原始文本 (部分): 就最近来说有两个事，lol某主播的前女友发文称其飞黄腾达后抛弃她。我个人的想法是看男方的回应，本来恋...\n",
      "  生成伪标签: 评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "[SEP]\n",
      "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "\n",
      "请以中文输出，不要使用Markdown格式，不要包含其他额外信息。\n",
      "\n",
      "\n",
      "[/INST]\n",
      "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "[SEP]\n",
      "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
      "评论对象 (Target) |\n"
     ]
    }
   ],
   "source": [
    "# --- 配置用于生成伪标签的LLM ---\n",
    "GENERATOR_MODEL_NAME_FOR_PSEUDO = \"/root/autodl-tmp/models/Qwen3-8B\"  # 示例：使用与微调相同的模型路径，或另一个更强的模型\n",
    "GENERATOR_USE_QUANTIZATION_FOR_PSEUDO = True\n",
    "GENERATOR_QUANTIZATION_TYPE_FOR_PSEUDO = \"nf4\"\n",
    "\n",
    "# 用于生成伪标签的提示模板 (与微调的PROMPT_TEMPLATE类似，但不包含 \"模型输出：\" 后的答案部分)\n",
    "# 注意：这里的 GENERATOR_PROMPT_TEMPLATE 与主 PROMPT_TEMPLATE 几乎一致，\n",
    "# 确保 \"模型输出：\" 之后是空的，以便LLM填充。\n",
    "GENERATOR_PROMPT_TEMPLATE = \"\"\"<s>[INST] <<SYS>>\n",
    "\n",
    "你是一个专业的中文社交媒体内容分析助手，专门用于细粒度片段级仇恨言论识别。请根据用户提供的文本，识别其中存在的仇恨言论或非仇恨的评论性言论，并按照以下格式输出一个或多个四元组，注意：请不要启用思考模式！：\n",
    "评论对象 (Target) | 论点 (Argument) | 目标群体 (Targeted Group) | 是否仇恨 (Hateful) [END]\n",
    "详细说明：\n",
    "1.  **评论对象 (Target)：** 帖子中被评论或提及的具体人物、群体、事物或概念。如果是针对文本中隐含的、没有明确指出的对象，或者评论是泛指，则设为 \"NULL\"。\n",
    "2.  **论点 (Argument)：** 针对“评论对象”所发表的核心观点、描述或行为，应为文本中的一个关键信息片段。\n",
    "3.  **目标群体 (Targeted Group)：** 指该“评论对象-论点”所涉及或指向的社会群体。必须从以下预设类别中选择：\n",
    "    * `Region`：针对特定地域（国家、省份、城市等）人群的评论。\n",
    "    * `Racism`：针对特定种族或民族人群的评论。\n",
    "    * `Sexism`：针对特定性别人群（男性、女性）的评论，或性别歧视、刻板印象。\n",
    "    * `LGBTQ`：针对性少数群体的评论（如同性恋、跨性别等）。\n",
    "    * `others`：针对上述四类之外的特定群体（如特定职业、疾病群体、政治立场群体等）或不构成对特定社会群体的攻击，而是个人攻击、观点评论等。\n",
    "    * `non-hate`：不存在攻击群体。\n",
    "4.  **是否仇恨 (Hateful)：** 判断该“评论对象-论点”是否构成了对“目标群体”的仇恨言论。\n",
    "    * `hate`：构成仇恨。\n",
    "    * `non-hate`：不构成仇恨（包括中性、积极、或一般性负面评论但未达到仇恨程度）。\n",
    "格式要求：\n",
    "* 四元组内各元素之间用 \" | \"（空格竖杠空格）分隔。\n",
    "* 每个四元组必须以 \" [END]\"（空格[END]）结尾。\n",
    "* 如果一条评论中识别出多个独立的评论对象和论点，应输出多个四元组，不同四元组之间用 \" [SEP] \"（空格[SEP]空格）分隔。\n",
    "\n",
    "现在，请处理以下新的输入内容：\n",
    "<</SYS>>\n",
    "\n",
    "用户提供的文本如下：\n",
    "{input_text} [/INST]\n",
    "模型输出：\n",
    "\"\"\"\n",
    "\n",
    "pseudo_labels_list = []\n",
    "texts_for_pseudo_generation = []\n",
    "\n",
    "if raw_datasets and 'train' in raw_datasets and raw_datasets['train'] is not None:\n",
    "    texts_for_pseudo_generation = list(raw_datasets['train']['text'])\n",
    "    print(f\"准备为 {len(texts_for_pseudo_generation)} 条训练文本生成伪标签...\")\n",
    "\n",
    "    # --- 加载生成器LLM和Tokenizer ---\n",
    "    # 为避免与主模型冲突，使用不同的变量名\n",
    "    generator_model_instance = None\n",
    "    generator_tokenizer_instance = None\n",
    "    print(f\"正在从 '{GENERATOR_MODEL_NAME_FOR_PSEUDO}' 加载用于生成伪标签的LLM和Tokenizer...\")\n",
    "    try:\n",
    "        generator_tokenizer_instance = AutoTokenizer.from_pretrained(GENERATOR_MODEL_NAME_FOR_PSEUDO,\n",
    "                                                                     trust_remote_code=True)\n",
    "\n",
    "        generator_bnb_config = None\n",
    "        if GENERATOR_USE_QUANTIZATION_FOR_PSEUDO:\n",
    "            if GENERATOR_QUANTIZATION_TYPE_FOR_PSEUDO == \"nf4\" or GENERATOR_QUANTIZATION_TYPE_FOR_PSEUDO == \"fp4\":\n",
    "                generator_bnb_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True, bnb_4bit_quant_type=GENERATOR_QUANTIZATION_TYPE_FOR_PSEUDO,\n",
    "                    bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_use_double_quant=True,\n",
    "                )\n",
    "            elif GENERATOR_QUANTIZATION_TYPE_FOR_PSEUDO == \"int8\":\n",
    "                generator_bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "            print(f\"生成器LLM将使用量化: {GENERATOR_QUANTIZATION_TYPE_FOR_PSEUDO if generator_bnb_config else '无'}\")\n",
    "\n",
    "        generator_model_instance = AutoModelForCausalLM.from_pretrained(\n",
    "            GENERATOR_MODEL_NAME_FOR_PSEUDO,\n",
    "            quantization_config=generator_bnb_config,\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        generator_model_instance.eval()\n",
    "\n",
    "        if generator_tokenizer_instance.pad_token is None:\n",
    "            generator_tokenizer_instance.pad_token = generator_tokenizer_instance.eos_token\n",
    "            if generator_model_instance.config.pad_token_id is None:\n",
    "                generator_model_instance.config.pad_token_id = generator_tokenizer_instance.pad_token_id\n",
    "            print(f\"生成器Tokenizer的pad_token已设置为eos_token: '{generator_tokenizer_instance.eos_token}'\")\n",
    "\n",
    "        print(\"生成器LLM和Tokenizer加载成功。\")\n",
    "\n",
    "        GENERATION_BATCH_SIZE = 8  # 伪标签生成批次大小\n",
    "\n",
    "        generation_config_pseudo = GenerationConfig(\n",
    "            max_new_tokens=MAX_TARGET_LENGTH,\n",
    "            num_beams=1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=generator_tokenizer_instance.pad_token_id if generator_tokenizer_instance.pad_token_id is not None else generator_tokenizer_instance.eos_token_id,\n",
    "            eos_token_id=generator_tokenizer_instance.eos_token_id\n",
    "        )\n",
    "\n",
    "        for i in tqdm(range(0, len(texts_for_pseudo_generation), GENERATION_BATCH_SIZE), desc=\"生成伪标签\"):\n",
    "            batch_texts = texts_for_pseudo_generation[i: i + GENERATION_BATCH_SIZE]\n",
    "            batch_prompts = [GENERATOR_PROMPT_TEMPLATE.format(input_text=text) for text in batch_texts]\n",
    "\n",
    "            inputs = generator_tokenizer_instance(\n",
    "                batch_prompts,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=MAX_INPUT_LENGTH - MAX_TARGET_LENGTH\n",
    "            ).to(generator_model_instance.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = generator_model_instance.generate(**inputs, generation_config=generation_config_pseudo)\n",
    "\n",
    "            full_decoded_outputs = generator_tokenizer_instance.batch_decode(outputs, skip_special_tokens=True,\n",
    "                                                                             clean_up_tokenization_spaces=True)\n",
    "            keyword_separator_pseudo = \"模型输出：\"\n",
    "\n",
    "            for full_output_text in full_decoded_outputs:\n",
    "                answer_part_str = \"\"\n",
    "                if keyword_separator_pseudo in full_output_text:\n",
    "                    answer_part_str = full_output_text.split(keyword_separator_pseudo, 1)[-1].strip()\n",
    "                else:\n",
    "                    original_prompt_text_no_answer = \\\n",
    "                    GENERATOR_PROMPT_TEMPLATE.format(input_text=\"DUMMY\").split(keyword_separator_pseudo)[0]\n",
    "                    if full_output_text.startswith(original_prompt_text_no_answer.split(\"用户提供的文本如下：\")[0]):\n",
    "                        answer_part_str = full_output_text\n",
    "                    else:\n",
    "                        answer_part_str = full_output_text\n",
    "                pseudo_labels_list.append(answer_part_str)\n",
    "\n",
    "        print(f\"成功为 {len(pseudo_labels_list)} 条文本生成了伪标签。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"加载生成器LLM或生成伪标签过程中发生错误: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        print(\"将使用空的伪标签列表。\")\n",
    "        pseudo_labels_list = []\n",
    "    finally:\n",
    "        # 清理生成器模型以释放显存\n",
    "        if 'generator_model_instance' in locals() and generator_model_instance is not None:\n",
    "            del generator_model_instance\n",
    "        if 'generator_tokenizer_instance' in locals() and generator_tokenizer_instance is not None:\n",
    "            del generator_tokenizer_instance\n",
    "        if 'inputs' in locals() and inputs is not None: del inputs\n",
    "        if 'outputs' in locals() and outputs is not None: del outputs\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"生成器LLM及相关资源已尝试清理。\")\n",
    "else:\n",
    "    print(\"警告: 原始数据集 'raw_datasets' 未加载，无法生成伪标签。\")\n",
    "    pseudo_labels_list = []\n",
    "\n",
    "if pseudo_labels_list:\n",
    "    print(\"\\n生成的一些伪标签样本:\")\n",
    "    for i in range(min(3, len(pseudo_labels_list))):\n",
    "        print(f\"  原始文本 (部分): {texts_for_pseudo_generation[i][:50]}...\")\n",
    "        print(f\"  生成伪标签: {pseudo_labels_list[i]}\")\n",
    "else:\n",
    "    print(\"\\n未能生成或加载任何伪标签。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e63aab90f691bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告：单元格8的 'parse_quadruples' 函数定义先于此单元格执行。将使用临时占位符。\n",
      "开始基于LLM生成的伪标签（作为负例）进行对比数据增强...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "创建对比增强SFT数据: 100%|██████████| 4000/4000 [00:00<00:00, 647493.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对比数据增强完成。\n",
      "原始训练样本数: 4000\n",
      "额外创建了 3997 个对比增强样本。\n",
      "对比增强SFT数据准备完成。训练集现在包含 7997 条样本。\n",
      "增强后训练集的第一个样本 text (可能为原始): 没爹的黑孩到处扔...\n",
      "增强后训练集的第一个样本 quadruple: 没爹的黑孩 | 到处扔 | Racism | hate [END]\n",
      "一个对比增强样本的 text (部分): 原始文本内容：\n",
      "\"大丈夫能屈能伸呐🐶\"\n",
      "\n",
      "一个AI助手针对以上文本给出了如下可能是错误或不完善的四元组提取结果：\n",
      "\"<</s>>\n",
      "\n",
      "好的，我需要分析用户提供的文本：“大丈夫能屈能伸呐🐶”。首先，确定评论对象（Target）。这里的“大丈夫”指的是男性，但具体指向不明确，可能是泛指男性或某个特定人物，但文本中没有明确对象，所以设为NULL。接下来是论点（Argument），即“能屈能伸”，这是对“大丈夫”的描述，强调其适应能力。目标群体（Targeted Group）需要从预设类别中选择。这里讨论...\n",
      "该增强样本的目标 quadruple: 大丈夫 | 能屈能伸呐🐶 | non-hate | non-hate [END]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ENABLE_CONTRASTIVE_AUGMENTATION_WITH_NEGATIVES = True\n",
    "\n",
    "if 'parse_quadruples' not in globals():\n",
    "    def parse_quadruples_placeholder(text_str_dummy):\n",
    "        if not text_str_dummy: return []\n",
    "        quads = []\n",
    "        parts = text_str_dummy.split(SEP_TOKEN if 'SEP_TOKEN' in globals() else \"[SEP]\")\n",
    "        for part in parts:\n",
    "            part_c = part.strip()\n",
    "            if part_c.endswith(END_TOKEN if 'END_TOKEN' in globals() else \"[END]\"):\n",
    "                part_c = part_c[:-len(END_TOKEN if 'END_TOKEN' in globals() else \"[END]\")].strip()\n",
    "            if not part_c: continue\n",
    "            elements = [e.strip() for e in part_c.split(\" | \")]\n",
    "            if len(elements) == 4:\n",
    "                quads.append(elements)\n",
    "        return quads\n",
    "\n",
    "\n",
    "    parse_quadruples_fn_to_use = parse_quadruples_placeholder\n",
    "    print(\"警告：单元格8的 'parse_quadruples' 函数定义先于此单元格执行。将使用临时占位符。\")\n",
    "else:\n",
    "    parse_quadruples_fn_to_use = parse_quadruples\n",
    "\n",
    "if ENABLE_CONTRASTIVE_AUGMENTATION_WITH_NEGATIVES and \\\n",
    "        'raw_datasets' in locals() and raw_datasets and \\\n",
    "        'pseudo_labels_list' in locals() and \\\n",
    "        len(pseudo_labels_list) == len(raw_datasets['train']):\n",
    "\n",
    "    print(f\"开始基于LLM生成的伪标签（作为负例）进行对比数据增强...\")\n",
    "\n",
    "    original_train_texts = list(raw_datasets['train']['text'])\n",
    "    original_train_quads = list(raw_datasets['train']['quadruples_str'])\n",
    "\n",
    "    contrastive_augmented_texts = []\n",
    "    contrastive_augmented_quads = []\n",
    "\n",
    "    num_augmented_samples_created = 0\n",
    "\n",
    "    for i in tqdm(range(len(original_train_texts)), desc=\"创建对比增强SFT数据\"):\n",
    "        original_text_content = original_train_texts[i]\n",
    "        true_quad_str = original_train_quads[i]\n",
    "        negative_pseudo_quad_str = pseudo_labels_list[i]\n",
    "\n",
    "        contrastive_augmented_texts.append(original_text_content)\n",
    "        contrastive_augmented_quads.append(true_quad_str)\n",
    "\n",
    "        if negative_pseudo_quad_str and negative_pseudo_quad_str.strip() and \\\n",
    "                negative_pseudo_quad_str.strip() != true_quad_str.strip():\n",
    "            new_input_for_prompt = (\n",
    "                f\"原始文本内容：\\n\\\"{original_text_content}\\\"\\n\\n\"\n",
    "                f\"一个AI助手针对以上文本给出了如下可能是错误或不完善的四元组提取结果：\\n\"\n",
    "                f\"\\\"{negative_pseudo_quad_str}\\\"\\n\\n\"\n",
    "                f\"请你忽略上述AI助手的提取结果（它可能包含错误），并严格按照指令，根据“原始文本内容”重新分析并给出正确的四元组。\"\n",
    "            )\n",
    "\n",
    "            contrastive_augmented_texts.append(new_input_for_prompt)\n",
    "            contrastive_augmented_quads.append(true_quad_str)\n",
    "            num_augmented_samples_created += 1\n",
    "\n",
    "    print(f\"对比数据增强完成。\")\n",
    "    print(f\"原始训练样本数: {len(original_train_texts)}\")\n",
    "    print(f\"额外创建了 {num_augmented_samples_created} 个对比增强样本。\")\n",
    "\n",
    "    if num_augmented_samples_created > 0 or len(contrastive_augmented_texts) != len(original_train_texts):\n",
    "        contrastive_augmented_train_dataset = Dataset.from_dict({\n",
    "            \"text\": contrastive_augmented_texts,\n",
    "            \"quadruples_str\": contrastive_augmented_quads\n",
    "        })\n",
    "\n",
    "        raw_datasets['train'] = contrastive_augmented_train_dataset\n",
    "        print(f\"对比增强SFT数据准备完成。训练集现在包含 {len(raw_datasets['train'])} 条样本。\")\n",
    "        if len(raw_datasets['train']) > 0:\n",
    "            print(f\"增强后训练集的第一个样本 text (可能为原始): {raw_datasets['train'][0]['text'][:150]}...\")\n",
    "            print(f\"增强后训练集的第一个样本 quadruple: {raw_datasets['train'][0]['quadruples_str']}\")\n",
    "            if len(raw_datasets['train']) > len(original_train_texts):\n",
    "                print(f\"一个对比增强样本的 text (部分): {raw_datasets['train'][-1]['text'][:250]}...\")\n",
    "                print(f\"该增强样本的目标 quadruple: {raw_datasets['train'][-1]['quadruples_str']}\")\n",
    "    else:\n",
    "        print(\"没有新的对比增强样本被添加到训练集（可能因为所有伪标签都与真实标签相同，或者伪标签为空）。\")\n",
    "\n",
    "else:\n",
    "    if not ENABLE_CONTRASTIVE_AUGMENTATION_WITH_NEGATIVES:\n",
    "        print(\"基于LLM负例的对比数据增强被禁用。\")\n",
    "    else:\n",
    "        print(\n",
    "            \"警告: 未执行基于LLM负例的对比数据增强，因为 'raw_datasets' 或 'pseudo_labels_list' 未正确准备或数量不匹配。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8304a0035d0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从 '/root/autodl-tmp/models/Qwen3-8B' 加载用于微调的Tokenizer...\n",
      "微调Tokenizer加载完成。\n",
      "微调Tokenizer的pad_token已设置为: '<|endoftext|>' (ID: 151643)\n"
     ]
    }
   ],
   "source": [
    "print(f\"正在从 '{MODEL_NAME}' 加载用于微调的Tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "print(\"微调Tokenizer加载完成。\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\n",
    "        f\"微调Tokenizer的pad_token未设置，已将其设置为eos_token: '{tokenizer.eos_token}' (ID: {tokenizer.eos_token_id})\")\n",
    "else:\n",
    "    print(f\"微调Tokenizer的pad_token已设置为: '{tokenizer.pad_token}' (ID: {tokenizer.pad_token_id})\")\n",
    "\n",
    "\n",
    "def preprocess_function_causal(examples):\n",
    "    full_prompts = []\n",
    "    input_texts_for_prompt = examples[\"text\"]\n",
    "    target_outputs = examples[\"quadruples_str\"]\n",
    "\n",
    "    for input_text, target_output in zip(input_texts_for_prompt, target_outputs):\n",
    "        input_text_str = str(input_text) if input_text is not None else \"\"\n",
    "        target_output_str = str(target_output) if target_output is not None else \"\"\n",
    "\n",
    "        prompt_part = PROMPT_TEMPLATE.format(input_text=input_text_str)\n",
    "        full_text = prompt_part + target_output_str + tokenizer.eos_token\n",
    "        full_prompts.append(full_text)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        full_prompts,\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "\n",
    "    labels = [list(ids) for ids in model_inputs[\"input_ids\"]]\n",
    "\n",
    "    for i in range(len(examples[\"text\"])):\n",
    "        current_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        current_labels = labels[i]\n",
    "\n",
    "        answer_part_str = str(examples[\"quadruples_str\"][i]) if examples[\"quadruples_str\"][i] is not None else \"\"\n",
    "        answer_tokens = tokenizer(answer_part_str + tokenizer.eos_token, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "        len_to_mask = len(current_input_ids) - len(answer_tokens)\n",
    "\n",
    "        if len_to_mask < 0:\n",
    "            if current_input_ids and current_input_ids[0] == tokenizer.bos_token_id:\n",
    "                len_to_mask = 1\n",
    "            else:\n",
    "                len_to_mask = 0\n",
    "\n",
    "        for j in range(min(len_to_mask, len(current_labels))):\n",
    "            current_labels[j] = -100\n",
    "\n",
    "        if answer_part_str and all(l == -100 for l in current_labels):\n",
    "            if current_labels:\n",
    "                current_labels[-1] = current_input_ids[-1]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe46af28c5e475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始对数据集进行tokenize和预处理 (适配Causal LM)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a1d09dbf0e4f52a8ecd1126e77efc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据tokenize和预处理完成:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 7997\n",
      "    })\n",
      "})\n",
      "\n",
      "Tokenize后的训练集样本 (检查input_ids和labels的屏蔽情况):\n",
      "  原始/增强后输入文本 (text): 没爹的黑孩到处扔\n",
      "  原始目标输出 (quadruples_str): 没爹的黑孩 | 到处扔 | Racism | hate [END]\n",
      "\n",
      "  Tokenized input_ids (前60): [44047, 30768, 64462, 60, 1115, 37931, 39071, 56568, 101909, 104715, 104811, 116253, 43815, 101042, 110498, 3837, 102093, 100751, 99338, 101425, 26381, 115076, 52334, 117828, 109445, 102450, 1773, 14880, 100345, 20002, 103008, 108704, 3837, 102450, 90919, 102670, 117828, 109445, 57191, 65676, 117828, 9370, 85641, 33071, 109445, 90395, 101892, 87752, 68805, 66017, 46944, 57191, 101213, 63703, 23305, 40027, 28311, 85641, 64429, 320]\n",
      "  Decoded input_ids (前60): <s>[INST] <<SYS>>\n",
      "你是一个专业的中文社交媒体内容分析助手，专门用于细粒度片段级仇恨言论识别。请根据用户提供的文本，识别其中存在的仇恨言论或非仇恨的评论性言论，并按照以下格式输出一个或多个四元组：\n",
      "评论对象 (\n",
      "\n",
      "  Tokenized labels (前60, -100表示已屏蔽): [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "  Decoded labels from first non-masked token (部分): 没爹的黑孩 | 到处扔 | Racism | hate [END]<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(\"开始对数据集进行tokenize和预处理 (适配Causal LM)...\")\n",
    "if 'raw_datasets' in locals() and raw_datasets and 'train' in raw_datasets and raw_datasets['train'] is not None:\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        preprocess_function_causal,\n",
    "        batched=True,\n",
    "        remove_columns=raw_datasets[\"train\"].column_names\n",
    "    )\n",
    "    print(\"\\n数据tokenize和预处理完成:\")\n",
    "    print(tokenized_datasets)\n",
    "\n",
    "    if tokenized_datasets and 'train' in tokenized_datasets and len(tokenized_datasets['train']) > 0:\n",
    "        print(f\"\\nTokenize后的训练集样本 (检查input_ids和labels的屏蔽情况):\")\n",
    "        sample_idx = 0\n",
    "        if sample_idx < len(tokenized_datasets['train']) and sample_idx < len(raw_datasets['train']):\n",
    "            print(f\"  原始/增强后输入文本 (text): {raw_datasets['train'][sample_idx]['text']}\")\n",
    "            print(f\"  原始目标输出 (quadruples_str): {raw_datasets['train'][sample_idx]['quadruples_str']}\")\n",
    "\n",
    "            tokenized_sample = tokenized_datasets['train'][sample_idx]\n",
    "            print(f\"\\n  Tokenized input_ids (前60): {tokenized_sample['input_ids'][:60]}\")\n",
    "            print(f\"  Decoded input_ids (前60): {tokenizer.decode(tokenized_sample['input_ids'][:60])}\")\n",
    "\n",
    "            print(f\"\\n  Tokenized labels (前60, -100表示已屏蔽): {tokenized_sample['labels'][:60]}\")\n",
    "\n",
    "            first_label_idx = -1\n",
    "            for idx, lbl_id in enumerate(tokenized_sample['labels']):\n",
    "                if lbl_id != -100:\n",
    "                    first_label_idx = idx\n",
    "                    break\n",
    "\n",
    "            if first_label_idx != -1:\n",
    "                decoded_label_part = tokenizer.decode(\n",
    "                    [l for l in tokenized_sample['labels'][first_label_idx:] if l != -100])\n",
    "                print(f\"  Decoded labels from first non-masked token (部分): {decoded_label_part}\")\n",
    "            else:\n",
    "                print(\"  注意：该样本的所有标签都被屏蔽了。\")\n",
    "                if raw_datasets['train'][sample_idx]['quadruples_str']:\n",
    "                    print(\n",
    "                        f\"  原始目标输出非空 ('{raw_datasets['train'][sample_idx]['quadruples_str']}'), 但所有标签被屏蔽，请仔细检查preprocess_function_causal中的屏蔽逻辑。\")\n",
    "        else:\n",
    "            print(f\"警告：选择的样本索引 {sample_idx} 超出训练集范围。\")\n",
    "    else:\n",
    "        print(\"\\n警告: Tokenize后的数据集为空或不完整。\")\n",
    "else:\n",
    "    print(\"错误: 'raw_datasets' 或其训练集未定义/为空，无法进行tokenize。请先成功执行数据加载和（可选的）增强单元格。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a265c566257823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备从 '/root/autodl-tmp/models/Qwen3-8B' 加载用于微调的Causal LM...\n",
      "微调模型将使用4-bit量化 (nf4) 加载。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22722e81a45046ecaaa4d9214fecc055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用于微调的模型 '/root/autodl-tmp/models/Qwen3-8B' 加载完成。\n",
      "微调模型配置的pad_token_id已设置为tokenizer的pad_token_id: 151643\n",
      "\n",
      "为微调模型启用LoRA。\n",
      "检测到微调模型已量化加载，准备k-bit训练...\n",
      "微调模型已为k-bit训练准备就绪。梯度检查点将启用。\n",
      "LoRA配置已创建:\n",
      "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=16, target_modules={'up_proj', 'down_proj', 'v_proj', 'gate_proj', 'o_proj', 'q_proj', 'k_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n",
      "\n",
      "LoRA适配器已应用到微调模型。\n",
      "trainable params: 43,646,976 || all params: 8,234,382,336 || trainable%: 0.5301\n",
      "当前微调模型所在设备: cuda:0\n",
      "微调模型层设备分布: {'': 0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"准备从 '{MODEL_NAME}' 加载用于微调的Causal LM...\")\n",
    "\n",
    "bnb_config_finetune = None\n",
    "if USE_QUANTIZATION:\n",
    "    if QUANTIZATION_TYPE == \"nf4\" or QUANTIZATION_TYPE == \"fp4\":\n",
    "        bnb_config_finetune = BitsAndBytesConfig(\n",
    "            load_in_4bit=True, bnb_4bit_quant_type=QUANTIZATION_TYPE,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "        print(f\"微调模型将使用4-bit量化 ({QUANTIZATION_TYPE}) 加载。\")\n",
    "    elif QUANTIZATION_TYPE == \"int8\":\n",
    "        bnb_config_finetune = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        print(\"微调模型将使用8-bit量化加载。\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config_finetune,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "print(f\"用于微调的模型 '{MODEL_NAME}' 加载完成。\")\n",
    "\n",
    "if tokenizer.pad_token_id is not None and model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    print(f\"微调模型配置的pad_token_id已设置为tokenizer的pad_token_id: {tokenizer.pad_token_id}\")\n",
    "\n",
    "if hasattr(model, 'config') and model.config.model_type and \"qwen2\" in model.config.model_type.lower() and hasattr(\n",
    "        model, 'enable_input_require_grads'):\n",
    "    try:\n",
    "        model.enable_input_require_grads()\n",
    "        print(\"已为Qwen2微调模型调用 enable_input_require_grads()\")\n",
    "    except Exception as e_grad:\n",
    "        print(f\"为Qwen2微调模型调用 enable_input_require_grads() 时发生错误 (可能不需要或不适用): {e_grad}\")\n",
    "\n",
    "if USE_LORA:\n",
    "    print(\"\\n为微调模型启用LoRA。\")\n",
    "    use_grad_ckpt_for_lora = True\n",
    "\n",
    "    if hasattr(model, \"is_loaded_in_8bit\") or hasattr(model, \"is_loaded_in_4bit\") or (\n",
    "            USE_QUANTIZATION and bnb_config_finetune is not None):\n",
    "        print(\"检测到微调模型已量化加载，准备k-bit训练...\")\n",
    "        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=use_grad_ckpt_for_lora)\n",
    "        print(f\"微调模型已为k-bit训练准备就绪。梯度检查点将{'启用' if use_grad_ckpt_for_lora else '禁用'}。\")\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=LORA_R, lora_alpha=LORA_ALPHA, target_modules=LORA_TARGET_MODULES,\n",
    "        lora_dropout=LORA_DROPOUT, bias=\"none\", task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "    print(\"LoRA配置已创建:\")\n",
    "    print(lora_config)\n",
    "\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    print(\"\\nLoRA适配器已应用到微调模型。\")\n",
    "    model.print_trainable_parameters()\n",
    "else:\n",
    "    print(\"\\n未启用LoRA，将进行全参数微调。\")\n",
    "\n",
    "print(f\"当前微调模型所在设备: {model.device}\")\n",
    "if hasattr(model, 'hf_device_map'):\n",
    "    print(f\"微调模型层设备分布: {model.hf_device_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8b9e84f0c0fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估指标相关函数已定义 (在训练期间将不使用)。\n",
      "DEBUG: 已将 parse_quadruples_fn_to_use 更新为本单元格的完整定义。\n"
     ]
    }
   ],
   "source": [
    "#评估指标计算函数 （但由于老是OOM所以取消了验证阶段)\n",
    "def parse_quadruples(text_str):\n",
    "    quadruples = []\n",
    "    if not isinstance(text_str, str) or not text_str.strip():\n",
    "        return []\n",
    "\n",
    "    parts = text_str.split(SEP_TOKEN)\n",
    "    for part_idx, part in enumerate(parts):\n",
    "        part_cleaned = part.strip()\n",
    "\n",
    "        if part_cleaned.endswith(END_TOKEN):\n",
    "            part_cleaned = part_cleaned[:-len(END_TOKEN)].strip()\n",
    "        elif not part_cleaned and part_idx == len(parts) - 1:\n",
    "            continue\n",
    "\n",
    "        if not part_cleaned:\n",
    "            continue\n",
    "\n",
    "        elements = [e.strip() for e in part_cleaned.split(\" | \")]\n",
    "\n",
    "        if len(elements) == 4:\n",
    "            quadruples.append(elements)\n",
    "    return quadruples\n",
    "\n",
    "\n",
    "def calculate_f1_metrics(preds_quads_list, labels_quads_list):\n",
    "    true_positives_hard = 0\n",
    "    predicted_positives_hard = 0\n",
    "    actual_positives_hard = 0\n",
    "    true_positives_soft = 0\n",
    "    predicted_positives_soft = 0\n",
    "    actual_positives_soft = 0\n",
    "\n",
    "    for pred_quads_for_sample, gold_quads_for_sample in zip(preds_quads_list, labels_quads_list):\n",
    "        predicted_positives_hard += len(pred_quads_for_sample)\n",
    "        actual_positives_hard += len(gold_quads_for_sample)\n",
    "        predicted_positives_soft += len(pred_quads_for_sample)\n",
    "        actual_positives_soft += len(gold_quads_for_sample)\n",
    "\n",
    "        matched_gold_indices_hard = set()\n",
    "        for p_quad in pred_quads_for_sample:\n",
    "            for i, g_quad in enumerate(gold_quads_for_sample):\n",
    "                if i in matched_gold_indices_hard: continue\n",
    "                if p_quad == g_quad:\n",
    "                    true_positives_hard += 1\n",
    "                    matched_gold_indices_hard.add(i)\n",
    "                    break\n",
    "\n",
    "        matched_gold_indices_soft = set()\n",
    "        for p_quad in pred_quads_for_sample:\n",
    "            if len(p_quad) != 4: continue\n",
    "            for i, g_quad in enumerate(gold_quads_for_sample):\n",
    "                if len(g_quad) != 4: continue\n",
    "                if i in matched_gold_indices_soft: continue\n",
    "                if p_quad[2].strip().lower() == g_quad[2].strip().lower() and \\\n",
    "                        p_quad[3].strip().lower().startswith(g_quad[3].strip().lower().split(\" \")[0]):\n",
    "                    sim_target = difflib.SequenceMatcher(None, p_quad[0], g_quad[0]).ratio()\n",
    "                    sim_argument = difflib.SequenceMatcher(None, p_quad[1], g_quad[1]).ratio()\n",
    "                    if sim_target > 0.5 and sim_argument > 0.5:\n",
    "                        true_positives_soft += 1\n",
    "                        matched_gold_indices_soft.add(i)\n",
    "                        break\n",
    "\n",
    "    precision_hard = true_positives_hard / predicted_positives_hard if predicted_positives_hard > 0 else 0\n",
    "    recall_hard = true_positives_hard / actual_positives_hard if actual_positives_hard > 0 else 0\n",
    "    f1_hard = 2 * (precision_hard * recall_hard) / (precision_hard + recall_hard) if (\n",
    "                                                                                                 precision_hard + recall_hard) > 0 else 0\n",
    "    precision_soft = true_positives_soft / predicted_positives_soft if predicted_positives_soft > 0 else 0\n",
    "    recall_soft = true_positives_soft / actual_positives_soft if actual_positives_soft > 0 else 0\n",
    "    f1_soft = 2 * (precision_soft * recall_soft) / (precision_soft + recall_soft) if (\n",
    "                                                                                                 precision_soft + recall_soft) > 0 else 0\n",
    "    avg_f1 = (f1_hard + f1_soft) / 2\n",
    "    return {\n",
    "        \"f1_hard\": f1_hard, \"precision_hard\": precision_hard, \"recall_hard\": recall_hard,\n",
    "        \"f1_soft\": f1_soft, \"precision_soft\": precision_soft, \"recall_soft\": recall_soft,\n",
    "        \"avg_f1\": avg_f1\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics_causal(eval_preds):\n",
    "    generated_token_ids, label_ids_from_input = eval_preds\n",
    "    decoded_preds_full_str = tokenizer.batch_decode(generated_token_ids, skip_special_tokens=True,\n",
    "                                                    clean_up_tokenization_spaces=True)\n",
    "\n",
    "    pred_answer_strs = []\n",
    "    keyword_separator = \"模型输出：\"\n",
    "    for full_pred_text in decoded_preds_full_str:\n",
    "        if keyword_separator in full_pred_text:\n",
    "            pred_answer_strs.append(full_pred_text.split(keyword_separator, 1)[-1].strip())\n",
    "        else:\n",
    "            pred_answer_strs.append(full_pred_text)\n",
    "\n",
    "    processed_label_ids = np.where(label_ids_from_input != -100, label_ids_from_input, tokenizer.pad_token_id)\n",
    "    decoded_labels_full_str = tokenizer.batch_decode(processed_label_ids, skip_special_tokens=True,\n",
    "                                                     clean_up_tokenization_spaces=True)\n",
    "    actual_target_strs = []\n",
    "    for full_label_text in decoded_labels_full_str:\n",
    "        if keyword_separator in full_label_text:\n",
    "            actual_target_strs.append(full_label_text.split(keyword_separator, 1)[-1].strip())\n",
    "        else:\n",
    "            actual_target_strs.append(\"\")\n",
    "\n",
    "    pred_quads_list = [parse_quadruples(p_str) for p_str in pred_answer_strs]\n",
    "    label_quads_list = [parse_quadruples(l_str) for l_str in actual_target_strs]\n",
    "\n",
    "    results = calculate_f1_metrics(pred_quads_list, label_quads_list)\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"评估指标相关函数已定义 (在训练期间将不使用)。\")\n",
    "if 'parse_quadruples_fn_to_use' in globals() and parse_quadruples_fn_to_use.__name__ == 'parse_quadruples_placeholder':\n",
    "    parse_quadruples_fn_to_use = parse_quadruples\n",
    "    print(\"DEBUG: 已将 parse_quadruples_fn_to_use 更新为本单元格的完整定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28b1e756d2e5eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练参数 (TrainingArguments) 配置完成。评估已被禁用，模型将在每个epoch结束时保存。\n",
      "数据整理器 (DataCollatorForSeq2Seq) 初始化完成。\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    # 移除了 per_device_eval_batch_size 因为不做评估\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "\n",
    "    do_eval=False,\n",
    "    eval_strategy=\"no\",\n",
    "    # eval_steps, metric_for_best_model, greater_is_better 已移除\n",
    "\n",
    "    save_strategy=\"epoch\",  # 在每个epoch结束后保存一个checkpoint\n",
    "    save_total_limit=1,  # 只保留最后一个checkpoint\n",
    "    load_best_model_at_end=False,  # 禁用此功能，因为没有验证集来确定“最佳”模型\n",
    "\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,  # 设置一个固定的日志记录步数\n",
    "\n",
    "    fp16=(torch.cuda.is_available() and not USE_QUANTIZATION),\n",
    "    bf16=(torch.cuda.is_bf16_supported() and not USE_QUANTIZATION),\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    seed=SEED,\n",
    "    optim=\"paged_adamw_8bit\" if USE_QUANTIZATION else \"adamw_torch\",\n",
    "    remove_unused_columns=True,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    ")\n",
    "print(\"训练参数 (TrainingArguments) 配置完成。评估已被禁用，模型将在每个epoch结束时保存。\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, model=model, label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=8 if (training_args.fp16 or training_args.bf16) else None\n",
    ")\n",
    "print(\"数据整理器 (DataCollatorForSeq2Seq) 初始化完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecd26deb3e217169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8124/1385592710.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 初始化完成 (无验证模式)。\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\n",
    "        \"train\"] if 'tokenized_datasets' in locals() and tokenized_datasets and \"train\" in tokenized_datasets else None,\n",
    "    eval_dataset=None,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=None,\n",
    "    callbacks=[]  \n",
    ")\n",
    "print(\"Trainer 初始化完成 (无验证模式)。\")\n",
    "if not ('tokenized_datasets' in locals() and tokenized_datasets and \"train\" in tokenized_datasets and\n",
    "        tokenized_datasets[\"train\"]):\n",
    "    print(\"警告: Trainer的训练集未正确设置。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620759a4f617c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "即将开始模型训练...\n",
      "开始纯训练流程 (无中间评估)...\n"
     ]
    }
   ],
   "source": [
    "print(\"即将开始模型训练...\")\n",
    "if trainer.train_dataset is None:\n",
    "    print(\"错误: 训练数据集未设置，无法开始训练。\")\n",
    "else:\n",
    "    try:\n",
    "        # 这部分配置对于后续的推理依然有用，予以保留\n",
    "        if model.generation_config is None:\n",
    "            model.generation_config = GenerationConfig.from_model_config(model.config)\n",
    "            print(\"已为模型设置默认的GenerationConfig。\")\n",
    "\n",
    "        model.generation_config.max_new_tokens = MAX_TARGET_LENGTH\n",
    "        model.generation_config.num_beams = 3\n",
    "        model.generation_config.early_stopping = True\n",
    "        if tokenizer.pad_token_id is not None:\n",
    "            model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "        if tokenizer.eos_token_id is not None:\n",
    "            model.generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "        print(\"开始纯训练流程 (无中间评估)...\")\n",
    "        train_result = trainer.train()\n",
    "        print(\"\\n模型训练完成!\")\n",
    "\n",
    "        print(f\"正在将最终的LoRA适配器权重保存到 '{OUTPUT_DIR}'...\")\n",
    "        trainer.save_model(OUTPUT_DIR)\n",
    "        tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "        print(f\"模型适配器和tokenizer已成功保存到 '{OUTPUT_DIR}'。\")\n",
    "\n",
    "        # 记录并保存训练过程的最终指标（如训练损失）\n",
    "        metrics = train_result.metrics\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "        print(\"\\n训练指标已记录和保存。\")\n",
    "        print(f\"最终训练统计指标: {metrics}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n模型训练过程中发生严重错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    #%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cec30d2c052b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用于预测的模型已准备好，当前设备: cuda:0\n",
      "预测/推理相关函数 (predict_quadruples_causal) 已定义。\n"
     ]
    }
   ],
   "source": [
    "model_to_predict = trainer.model if 'trainer' in locals() and hasattr(trainer, 'model') else None\n",
    "if model_to_predict:\n",
    "    model_to_predict.eval()\n",
    "    print(f\"用于预测的模型已准备好，当前设备: {model_to_predict.device}\")\n",
    "else:\n",
    "    print(\"警告: 'trainer.model' 未找到，无法设置 model_to_predict。示例预测和提交文件生成可能失败。\")\n",
    "\n",
    "\n",
    "def predict_quadruples_causal(text_list, model, tokenizer_pred, max_input_len_pred, max_target_gen_len_pred):\n",
    "    parsed_results_list = []\n",
    "    if model is None or tokenizer_pred is None:\n",
    "        print(\"错误: 预测所需的模型或tokenizer未提供。\")\n",
    "        return [\n",
    "            {\"original_text\": t, \"extracted_answer_string\": \"ERROR: Model/Tokenizer missing\", \"parsed_quadruples\": []}\n",
    "            for t in text_list]\n",
    "\n",
    "    for text_input in text_list:\n",
    "        prompt_for_inference = PROMPT_TEMPLATE.format(input_text=text_input)\n",
    "\n",
    "        max_prompt_len = max_input_len_pred - max_target_gen_len_pred\n",
    "        if max_prompt_len <= 0: max_prompt_len = max_input_len_pred // 2\n",
    "\n",
    "        inputs = tokenizer_pred(\n",
    "            prompt_for_inference, return_tensors=\"pt\", truncation=True,\n",
    "            max_length=max_prompt_len, padding=False\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            current_gen_config = GenerationConfig(**model.generation_config.to_dict())\n",
    "            current_gen_config.max_new_tokens = max_target_gen_len_pred\n",
    "\n",
    "            outputs = model.generate(**inputs, generation_config=current_gen_config)\n",
    "\n",
    "        full_generated_text = tokenizer_pred.decode(outputs[0], skip_special_tokens=True,\n",
    "                                                    clean_up_tokenization_spaces=True)\n",
    "\n",
    "        answer_part_str = \"\"\n",
    "        keyword_separator = \"模型输出：\"\n",
    "        split_parts = full_generated_text.split(keyword_separator, 1)\n",
    "        if len(split_parts) > 1:\n",
    "            answer_part_str = split_parts[1].strip()\n",
    "        else:\n",
    "            answer_part_str = full_generated_text\n",
    "\n",
    "        parsed_quads = parse_quadruples(answer_part_str)\n",
    "        parsed_results_list.append({\n",
    "            \"original_text\": text_input, \"full_generated_text\": full_generated_text,\n",
    "            \"extracted_answer_string\": answer_part_str, \"parsed_quadruples\": parsed_quads\n",
    "        })\n",
    "    return parsed_results_list\n",
    "\n",
    "\n",
    "print(\"预测/推理相关函数 (predict_quadruples_causal) 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd17ab5c4cc693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始运行示例预测...\n",
      "\n",
      "示例预测结果:\n",
      "原始文本: 那些同性恋真恶心，败坏社会风气。\n",
      "提取答案: 同性恋 | 真恶心 | LGBTQ | hate [END]\n",
      "解析四元组: [['同性恋', '真恶心', 'LGBTQ', 'hate']]\n",
      "------------------------------\n",
      "原始文本: 这道菜味道不错，下次还来。\n",
      "提取答案: 这道菜 | 味道不错 | non-hate | non-hate [END]\n",
      "解析四元组: [['这道菜', '味道不错', 'non-hate', 'non-hate']]\n",
      "------------------------------\n",
      "原始文本: 上海人就是排外，看不起外地人。\n",
      "提取答案: 上海人 | 排外 | Region | hate [SEP] 上海人 | 看不起外地人 | Region | hate [END]\n",
      "解析四元组: [['上海人', '排外', 'Region', 'hate'], ['上海人', '看不起外地人', 'Region', 'hate']]\n",
      "------------------------------\n",
      "原始文本: 黑人都是罪犯，应该被赶走。\n",
      "提取答案: 黑人 | 罪犯 | Racism | hate [END]\n",
      "解析四元组: [['黑人', '罪犯', 'Racism', 'hate']]\n",
      "------------------------------\n",
      "原始文本: 你可真是头蠢驴，这都做不好。\n",
      "提取答案: 你 | 蠢驴 | non-hate | non-hate [END]\n",
      "解析四元组: [['你', '蠢驴', 'non-hate', 'non-hate']]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_test_texts_for_prediction = [\n",
    "    \"那些同性恋真恶心，败坏社会风气。\", \"这道菜味道不错，下次还来。\",\n",
    "    \"上海人就是排外，看不起外地人。\", \"黑人都是罪犯，应该被赶走。\",\n",
    "    \"你可真是头蠢驴，这都做不好。\"\n",
    "]\n",
    "print(\"\\n开始运行示例预测...\")\n",
    "if 'model_to_predict' in locals() and model_to_predict is not None:\n",
    "    predictions = predict_quadruples_causal(\n",
    "        sample_test_texts_for_prediction, model_to_predict, tokenizer,\n",
    "        MAX_INPUT_LENGTH, MAX_TARGET_LENGTH\n",
    "    )\n",
    "    print(\"\\n示例预测结果:\")\n",
    "    for item in predictions:\n",
    "        print(f\"原始文本: {item['original_text']}\")\n",
    "        print(f\"提取答案: {item['extracted_answer_string']}\")\n",
    "        print(f\"解析四元组: {item['parsed_quadruples']}\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"错误: 'model_to_predict' 未定义或为None。无法运行示例预测。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51016ed5040cd5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始处理官方测试文件: ./test1.json\n",
      "正在从 './test1.json' 加载官方测试数据...\n",
      "成功从 './test1.json' 加载了 2000 条测试数据。\n",
      "开始对 2000 条测试数据进行预测 (批次大小: 3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "官方测试集预测: 100%|██████████| 667/667 [2:12:58<00:00, 11.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "提交文件已成功生成: ./newsubmission.txt\n",
      "该文件包含 2000 行预测。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def load_official_test_data(file_path):\n",
    "    texts_to_predict = []\n",
    "    ids_from_test_data = []\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"错误: 测试文件 '{file_path}' 未找到。\")\n",
    "        return texts_to_predict, ids_from_test_data\n",
    "\n",
    "    print(f\"正在从 '{file_path}' 加载官方测试数据...\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            if not isinstance(data, list):\n",
    "                print(f\"错误: 测试文件 '{file_path}' 的顶级结构不是一个列表。请检查文件格式。\")\n",
    "                return texts_to_predict, ids_from_test_data\n",
    "\n",
    "            for item_num, item in enumerate(data, 1):\n",
    "                if isinstance(item, dict) and \"content\" in item and \"id\" in item:\n",
    "                    texts_to_predict.append(item[\"content\"])\n",
    "                    ids_from_test_data.append(item[\"id\"])\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"警告: 测试文件 '{file_path}' 中的第 {item_num} 项格式不正确或缺少 'id'/'content' 键，已跳过: {item}\")\n",
    "\n",
    "        print(f\"成功从 '{file_path}' 加载了 {len(texts_to_predict)} 条测试数据。\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"错误: 解析测试文件 '{file_path}' 时发生JSON解码错误。请检查文件是否为有效的JSON格式。\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载测试文件 '{file_path}' 时发生其他错误: {e}\")\n",
    "\n",
    "    return texts_to_predict, ids_from_test_data\n",
    "\n",
    "\n",
    "official_test_file_path_to_use = \"./test1.json\"\n",
    "\n",
    "if 'model_to_predict' not in locals() or model_to_predict is None:\n",
    "    print(\"错误: 'model_to_predict' 未定义。无法进行官方测试数据预测。\")\n",
    "elif 'tokenizer' not in locals() or tokenizer is None:\n",
    "    print(\"错误: 'tokenizer' 未定义。无法进行官方测试数据预测。\")\n",
    "elif not os.path.exists(official_test_file_path_to_use):\n",
    "    print(f\"错误: 测试文件路径 '{official_test_file_path_to_use}' 不存在。\")\n",
    "else:\n",
    "    print(f\"\\n开始处理官方测试文件: {official_test_file_path_to_use}\")\n",
    "    official_test_texts, official_test_ids = load_official_test_data(official_test_file_path_to_use)\n",
    "\n",
    "    if official_test_texts:\n",
    "        submission_outputs_strings = []\n",
    "        inference_batch_size = EVAL_BATCH_SIZE\n",
    "        print(f\"开始对 {len(official_test_texts)} 条测试数据进行预测 (批次大小: {inference_batch_size})...\")\n",
    "        for i in tqdm(range(0, len(official_test_texts), inference_batch_size), desc=\"官方测试集预测\"):\n",
    "            batch_texts = official_test_texts[i: i + inference_batch_size]\n",
    "            batch_predictions = predict_quadruples_causal(\n",
    "                batch_texts, model_to_predict, tokenizer,\n",
    "                MAX_INPUT_LENGTH, MAX_TARGET_LENGTH\n",
    "            )\n",
    "            for item_prediction in batch_predictions:\n",
    "                submission_outputs_strings.append(item_prediction['extracted_answer_string'])\n",
    "\n",
    "        submission_file_path = \"./newsubmission.txt\"\n",
    "        try:\n",
    "            with open(submission_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                for line_content in submission_outputs_strings:\n",
    "                    f.write(line_content + \"\\n\")\n",
    "            print(f\"\\n提交文件已成功生成: {submission_file_path}\")\n",
    "            print(f\"该文件包含 {len(submission_outputs_strings)} 行预测。\")\n",
    "        except Exception as e:\n",
    "            print(f\"写入提交文件 '{submission_file_path}' 时发生错误: {e}\")\n",
    "    else:\n",
    "        print(f\"未能从 '{official_test_file_path_to_use}' 加载任何测试数据进行预测。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd24a67-cd28-438e-b9b0-9ad04606fc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a895508-0ae6-40c9-90cb-d45be5b637a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
